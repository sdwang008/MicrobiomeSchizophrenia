{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from skbio.stats.composition import ilr\n",
    "from skbio.stats.composition import clr\n",
    "from skbio.stats.composition import multiplicative_replacement\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "sns.set()\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PCors and Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "partials0 = []\n",
    "partials1 = []\n",
    "\n",
    "bootstrap_n = 100\n",
    "\n",
    "for i in range(bootstrap_n):\n",
    "    partials0.append(pd.read_csv(\"df0PCors/df0_PCor\"+str(i)+\".csv\", header=0))\n",
    "    partials1.append(pd.read_csv(\"df1PCors/df1_PCor\"+str(i)+\".csv\", header=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables0 = []\n",
    "tables1 = []\n",
    "\n",
    "for i in range(bootstrap_n):\n",
    "    table0 = pd.read_csv(\"df0tables/df0_table\"+str(i)+\".csv\", header=0)\n",
    "    names = {}\n",
    "    for c in table0.columns:\n",
    "        names[c] = c.replace(\"-\",\";\")\n",
    "    table0.rename(names, axis=1, inplace=True)\n",
    "    tables0.append(table0)\n",
    "\n",
    "    table1 = pd.read_csv(\"df1tables/df1_table\"+str(i)+\".csv\", header=0)\n",
    "    names = {}\n",
    "    for c in table1.columns:\n",
    "        names[c] = c.replace(\"-\",\";\")\n",
    "    table1.rename(names, axis=1, inplace=True)\n",
    "    tables1.append(table1)\n",
    "\n",
    "taxonomy = pd.read_csv('data/taxonomy1.csv', header=0).set_index('Genera')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes in the partial correlation matrix pulls top triangle and returns associations that are not 0 or -1\n",
    "def allAssociations(df):\n",
    "    df2 = df.copy()\n",
    "    df3 = df2.drop(columns=['Unnamed: 0']).copy()\n",
    "    indexRename = {}\n",
    "    count = 0\n",
    "    \n",
    "    for column in df3.columns:\n",
    "        indexRename[count] = column\n",
    "        count+=1\n",
    "        \n",
    "    df3.rename(index=indexRename, inplace=True)\n",
    "\n",
    "    df4 = df3.where(np.triu(np.ones(df3.shape)).astype(bool))\n",
    "    df4 = df4.stack().reset_index()\n",
    "    df4.columns = ['Node1','Node2','Association_Weight']\n",
    "    \n",
    "    for i in df4.index:\n",
    "        if df4.at[i,'Association_Weight'] == -1.0:\n",
    "            df4.drop(index=i, inplace=True)\n",
    "            \n",
    "    return(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "associations0 = []\n",
    "associations1 = []\n",
    "\n",
    "for i in range(100):\n",
    "    associations0.append(allAssociations(partials0[i]))\n",
    "    associations1.append(allAssociations(partials1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Node1</th>\n",
       "      <th>Node2</th>\n",
       "      <th>Association_Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k__Archaea.p__Euryarchaeota.c__Methanobacteria...</td>\n",
       "      <td>k__Bacteria.p__Actinobacteria.c__Actinobacteri...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k__Archaea.p__Euryarchaeota.c__Methanobacteria...</td>\n",
       "      <td>k__Bacteria.p__Actinobacteria.c__Actinobacteri...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k__Archaea.p__Euryarchaeota.c__Methanobacteria...</td>\n",
       "      <td>k__Bacteria.p__Actinobacteria.c__Actinobacteri...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k__Archaea.p__Euryarchaeota.c__Methanobacteria...</td>\n",
       "      <td>k__Bacteria.p__Actinobacteria.c__Actinobacteri...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>k__Archaea.p__Euryarchaeota.c__Methanobacteria...</td>\n",
       "      <td>k__Bacteria.p__Actinobacteria.c__Actinobacteri...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>k__Bacteria.p__Synergistetes.c__Synergistia.o_...</td>\n",
       "      <td>k__Bacteria.p__Synergistetes.c__Synergistia.o_...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>k__Bacteria.p__Synergistetes.c__Synergistia.o_...</td>\n",
       "      <td>k__Bacteria.p__Verrucomicrobia.c__Verrucomicro...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>k__Bacteria.p__Synergistetes.c__Synergistia.o_...</td>\n",
       "      <td>k__Bacteria.p__Synergistetes.c__Synergistia.o_...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>k__Bacteria.p__Synergistetes.c__Synergistia.o_...</td>\n",
       "      <td>k__Bacteria.p__Verrucomicrobia.c__Verrucomicro...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4654</th>\n",
       "      <td>k__Bacteria.p__Synergistetes.c__Synergistia.o_...</td>\n",
       "      <td>k__Bacteria.p__Verrucomicrobia.c__Verrucomicro...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4560 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Node1  \\\n",
       "1     k__Archaea.p__Euryarchaeota.c__Methanobacteria...   \n",
       "2     k__Archaea.p__Euryarchaeota.c__Methanobacteria...   \n",
       "3     k__Archaea.p__Euryarchaeota.c__Methanobacteria...   \n",
       "4     k__Archaea.p__Euryarchaeota.c__Methanobacteria...   \n",
       "5     k__Archaea.p__Euryarchaeota.c__Methanobacteria...   \n",
       "...                                                 ...   \n",
       "4648  k__Bacteria.p__Synergistetes.c__Synergistia.o_...   \n",
       "4649  k__Bacteria.p__Synergistetes.c__Synergistia.o_...   \n",
       "4651  k__Bacteria.p__Synergistetes.c__Synergistia.o_...   \n",
       "4652  k__Bacteria.p__Synergistetes.c__Synergistia.o_...   \n",
       "4654  k__Bacteria.p__Synergistetes.c__Synergistia.o_...   \n",
       "\n",
       "                                                  Node2  Association_Weight  \n",
       "1     k__Bacteria.p__Actinobacteria.c__Actinobacteri...                 0.0  \n",
       "2     k__Bacteria.p__Actinobacteria.c__Actinobacteri...                 0.0  \n",
       "3     k__Bacteria.p__Actinobacteria.c__Actinobacteri...                 0.0  \n",
       "4     k__Bacteria.p__Actinobacteria.c__Actinobacteri...                 0.0  \n",
       "5     k__Bacteria.p__Actinobacteria.c__Actinobacteri...                 0.0  \n",
       "...                                                 ...                 ...  \n",
       "4648  k__Bacteria.p__Synergistetes.c__Synergistia.o_...                 0.0  \n",
       "4649  k__Bacteria.p__Verrucomicrobia.c__Verrucomicro...                 0.0  \n",
       "4651  k__Bacteria.p__Synergistetes.c__Synergistia.o_...                 0.0  \n",
       "4652  k__Bacteria.p__Verrucomicrobia.c__Verrucomicro...                 0.0  \n",
       "4654  k__Bacteria.p__Verrucomicrobia.c__Verrucomicro...                 0.0  \n",
       "\n",
       "[4560 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "associations0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy import integrate\n",
    "\n",
    "def createSparseGrowthNetworkSpecies(partialdf, abundanceDF):\n",
    "    G = nx.Graph()\n",
    "       \n",
    "    for node in list(set(list(partialdf['Node1']) + list(partialdf['Node2']))):\n",
    "        nodename = node.replace(\".\",\";\").strip().split(\";\")\n",
    "        family = \"\"\n",
    "        for n in nodename:\n",
    "            if \"f__\" in n:\n",
    "                family = n\n",
    "        if isinstance(family, pd.Series):\n",
    "            family = family.iloc[0].strip()\n",
    "        G.add_node(node.replace(\".\",\";\").strip(), relativeAbundance=abundanceDF[node.replace(\".\",\";\").strip()].mean(), family=family)\n",
    "        # , genera=generaFindDF_master.at[node.replace(\".\",\"-\").strip(), 'Genus'].strip())\n",
    "    \n",
    "    for row in partialdf.index:\n",
    "        if abs(partialdf.at[row, 'Association_Weight']) > 0.01:\n",
    "            G.add_edge(partialdf.at[row, 'Node1'].replace(\".\",\";\").strip(),partialdf.at[row,'Node2'].replace(\".\",\";\").strip(), weight=partialdf.at[row, \"Association_Weight\"])\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    return G;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks0 = []\n",
    "networks1 = []\n",
    "\n",
    "import logging\n",
    "\n",
    "for i in range(100):\n",
    "    networks0.append(createSparseGrowthNetworkSpecies(associations0[i], tables0[i]))\n",
    "    networks1.append(createSparseGrowthNetworkSpecies(associations1[i], tables1[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community.quality import modularity\n",
    "\n",
    "def emergentNetworkProperties(network1, cohortName, partitions):\n",
    "    columnNames = {\"Network\":[],  \"Nodes\":[], \"Edges\":[], \"Positive_Edges\":[], \"Negative_Edges\":[], \"Nodes_in_Largest_Component\":[], \"Single_Nodes\":[], \"Density\":[], \"Average_Degree\":[], \"Average_Betweenness\":[], \"Modularity\":[], \"Connectedness\":[], \"ASPL\":[], \"Family_Assortativity\":[], \"Degree_Assortativity\":[], \"Transitivity\":[]}\n",
    "    ################################################\n",
    "    columnNames['Network'].append(cohortName)\n",
    "    columnNames['Nodes'].append(len(network1.nodes))\n",
    "    columnNames['Edges'].append(len(network1.edges))\n",
    "    ################################################\n",
    "    positiveEdges = []\n",
    "    negativeEdges = [] \n",
    "    \n",
    "    weights = nx.get_edge_attributes(network1, 'weight')\n",
    "    \n",
    "    for edge in list(network1.edges):\n",
    "        if float(weights[edge]) > 0.0:\n",
    "            positiveEdges.append(weights[edge])               \n",
    "        else:\n",
    "            negativeEdges.append(weights[edge])\n",
    "            \n",
    "    columnNames['Positive_Edges'].append(len(positiveEdges))\n",
    "    columnNames['Negative_Edges'].append(len(negativeEdges))\n",
    "    \n",
    "    #Find average degree of all nodes\n",
    "    degrees = []\n",
    "    for i in network1.nodes:\n",
    "        degrees.append(network1.degree(i))\n",
    "    avgDeg = np.mean(degrees)\n",
    "    columnNames['Average_Degree'].append(avgDeg)\n",
    "\n",
    "    # Betweenness Centrality\n",
    "    betweenness = nx.betweenness_centrality(network1, weight='weight')\n",
    "    avgBet = np.mean(list(betweenness.values()))\n",
    "    columnNames['Average_Betweenness'].append(avgBet)\n",
    "    \n",
    "    #Find Average Shortest Path Length (Average of over all connected components)\n",
    "    Gcc = sorted(nx.connected_components(network1), key=len, reverse=True)\n",
    "    L2 = []\n",
    "    for g in Gcc:\n",
    "        if len(g) > 1:\n",
    "            G0 = network1.subgraph(g)\n",
    "            L2.append(nx.average_shortest_path_length(G0))\n",
    "        else:\n",
    "            continue\n",
    "            weight=None\n",
    "            \n",
    "    columnNames['ASPL'] = np.mean(L2)\n",
    "    \n",
    "    columnNames['Modularity'].append(modularity(network1, partitions))\n",
    "    \n",
    "    #Find out how many nodes have no connections\n",
    "    counttt = 0\n",
    "    for i in list(nx.connected_components(network1)):\n",
    "        if len(i) >1:\n",
    "            continue\n",
    "        else:\n",
    "            counttt+=1\n",
    "    columnNames['Single_Nodes'] = counttt\n",
    "    \n",
    "    #Find how many nodes are in the biggest component of the graph\n",
    "    networkComponents = sorted(nx.connected_components(network1), key=len, reverse=True)\n",
    "    bigcomponent = network1.subgraph(networkComponents[0])\n",
    "    columnNames['Nodes_in_Largest_Component'] = len(list(nx.connected_components(bigcomponent))[0])\n",
    "    \n",
    "    \n",
    "    ###################################################################################\n",
    "    #Some statistics only work on connected components. Check if the network is connected.\n",
    "    if nx.is_connected(network1):\n",
    "        columnNames['Connectedness'].append(\"True\")\n",
    "        columnNames['Degree_Assortativity'].append(nx.degree_assortativity_coefficient(network1))\n",
    "        columnNames['Transitivity'].append(nx.transitivity(network1))\n",
    "        columnNames['Degree_Assortativity'].append(nx.degree_assortativity_coefficient(network1))\n",
    "        columnNames['Family_Assortativity'].append(nx.attribute_assortativity_coefficient(network1, 'family'))\n",
    "        columnNames['Transitivity'].append(nx.transitivity(network1))\n",
    "        columnNames['Density'].append(nx.density(network1))\n",
    "    else:\n",
    "        columnNames['Connectedness'].append(\"False\")\n",
    "        columnNames['Degree_Assortativity'].append(nx.degree_assortativity_coefficient(network1))\n",
    "        columnNames['Family_Assortativity'].append(nx.attribute_assortativity_coefficient(network1, 'family'))\n",
    "        columnNames['Transitivity'].append(nx.transitivity(network1))\n",
    "        columnNames['Density'].append(nx.density(network1))\n",
    "        \n",
    "    cohortDF = pd.DataFrame(columnNames)\n",
    "    return(cohortDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions0 = []\n",
    "partitions1 = []\n",
    "\n",
    "from networkx.algorithms.community.label_propagation import asyn_lpa_communities\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "for i in range(bootstrap_n):\n",
    "    partitions0.append(list(greedy_modularity_communities(networks0[i], weight='weight')))\n",
    "    partitions1.append(list(greedy_modularity_communities(networks1[i], weight='weight')))\n",
    "\n",
    "# for i in range(bootstrap_n):\n",
    "#     print(i)\n",
    "#     partitions0.append(list(asyn_lpa_communities(networks0[i], weight='weight')))\n",
    "#     partitions1.append(list(asyn_lpa_communities(networks1[i], weight='weight')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkProperties0 = []\n",
    "networkProperties1 = []\n",
    "networkProperty = []\n",
    "\n",
    "for i in range(bootstrap_n):\n",
    "    networkProperties0.append(emergentNetworkProperties(networks0[i], \"Healthy\", partitions0[i]).set_index(\"Network\"))\n",
    "    networkProperties1.append(emergentNetworkProperties(networks1[i], \"Schizophrenic\", partitions1[i]).set_index(\"Network\"))\n",
    "    networkProperty.append(pd.concat([networkProperties0[i], networkProperties1[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nodes</th>\n",
       "      <th>Edges</th>\n",
       "      <th>Positive_Edges</th>\n",
       "      <th>Negative_Edges</th>\n",
       "      <th>Nodes_in_Largest_Component</th>\n",
       "      <th>Single_Nodes</th>\n",
       "      <th>Density</th>\n",
       "      <th>Average_Degree</th>\n",
       "      <th>Average_Betweenness</th>\n",
       "      <th>Modularity</th>\n",
       "      <th>Connectedness</th>\n",
       "      <th>ASPL</th>\n",
       "      <th>Family_Assortativity</th>\n",
       "      <th>Degree_Assortativity</th>\n",
       "      <th>Transitivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Healthy</th>\n",
       "      <td>96</td>\n",
       "      <td>92</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>47</td>\n",
       "      <td>0.020175</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.720778</td>\n",
       "      <td>False</td>\n",
       "      <td>1.440873</td>\n",
       "      <td>0.081902</td>\n",
       "      <td>0.674733</td>\n",
       "      <td>0.661509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Nodes  Edges  Positive_Edges  Negative_Edges  \\\n",
       "Network                                                 \n",
       "Healthy     96     92              74              18   \n",
       "\n",
       "         Nodes_in_Largest_Component  Single_Nodes   Density  Average_Degree  \\\n",
       "Network                                                                       \n",
       "Healthy                          28            47  0.020175        1.916667   \n",
       "\n",
       "         Average_Betweenness  Modularity Connectedness      ASPL  \\\n",
       "Network                                                            \n",
       "Healthy             0.003642    0.720778         False  1.440873   \n",
       "\n",
       "         Family_Assortativity  Degree_Assortativity  Transitivity  \n",
       "Network                                                            \n",
       "Healthy              0.081902              0.674733      0.661509  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "networkProperties0[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliques0 = []\n",
    "cliques1 = []\n",
    "\n",
    "for i in range(bootstrap_n):\n",
    "    cliques0.append(list(nx.find_cliques(networks0[i])))\n",
    "    cliques1.append(list(nx.find_cliques(networks1[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnGoodCliques(network, cliqueSize):\n",
    "    cliques = []\n",
    "    for i in list(nx.enumerate_all_cliques(network)):\n",
    "        if len(i) == cliqueSize:\n",
    "            cliques.append(i)\n",
    "    return(cliques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the maximal cliques for all networks\n",
    "def findCliques(network1, network2, name1, name2, cliqueSize):\n",
    "    \n",
    "    names = []\n",
    "    \n",
    "    allCliques_temp1 = []\n",
    "    allCliques_temp2 = []\n",
    "\n",
    "    netNames = {}\n",
    "    \n",
    "    if network1 != 'No':\n",
    "        allCliques_temp1 = returnGoodCliques(network1, cliqueSize)\n",
    "        names.append(name1)\n",
    "        netNames[name1]=allCliques_temp1\n",
    "        \n",
    "    if network2 != 'No':\n",
    "        allCliques_temp2 = returnGoodCliques(network2, cliqueSize)    \n",
    "        names.append(name2)\n",
    "        netNames[name2]=allCliques_temp2\n",
    "        \n",
    "    \n",
    "    # Set one cohort as all cliques so far then add cliques that are unique from each cohort\n",
    "    allCliques = allCliques_temp1.copy()\n",
    "\n",
    "    for i in allCliques_temp2:\n",
    "        \n",
    "        countFlag = False\n",
    "        \n",
    "        for x in allCliques:\n",
    "            if sorted(i) == sorted(x):\n",
    "                countFlag = True\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        if countFlag == False:\n",
    "            allCliques.append(sorted(i))\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    ####################################################################################\n",
    "    # BUILD NEW DATAFRAME AND SAY IF ITS IN THAT COHORT OR NOT\n",
    "    \n",
    "    clidDic = {\"Clique\":[], \"Healthy\":[], \"Schizophrenic\":[]}\n",
    "   \n",
    "    for clique in allCliques:\n",
    "        \n",
    "        clidDic['Clique'].append(clique)\n",
    "        clique1count = False\n",
    "        clique2count = False\n",
    "        \n",
    "        for clique1 in allCliques_temp1:\n",
    "            \n",
    "            if sorted(clique1) == sorted(clique):\n",
    "                clique1count = True\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        if clique1count == True:\n",
    "            clidDic['Healthy'].append(\"Present\")\n",
    "        else:\n",
    "            clidDic['Healthy'].append(np.nan)\n",
    "        \n",
    "        ###############################################\n",
    "        \n",
    "        for clique2 in allCliques_temp2:\n",
    "            if sorted(clique2) == sorted(clique):\n",
    "                clique2count = True\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        if clique2count == True:\n",
    "            clidDic['Schizophrenic'].append(\"Present\")\n",
    "        else:\n",
    "            clidDic['Schizophrenic'].append(np.nan)\n",
    "            \n",
    "        ################################################\n",
    "        \n",
    "\n",
    "    cliqueDF = pd.DataFrame(data=clidDic).set_index(\"Clique\")\n",
    "    \n",
    "    return(cliqueDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCliques = []\n",
    "\n",
    "for i in range(bootstrap_n):\n",
    "    allCliques.append(findCliques(networks0[i], networks1[i], 'Healthy', 'Schizophrenic', 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "metric_names = list(networkProperty[0].columns)\n",
    "metric_names.remove(\"Connectedness\")\n",
    "metrics0 = {key: [] for key in metric_names}\n",
    "metrics1 = {key: [] for key in metric_names}\n",
    "\n",
    "for i in range(bootstrap_n):\n",
    "    for metric in metric_names:\n",
    "        metrics0[metric].append(networkProperties0[i][metric][0])\n",
    "        metrics1[metric].append(networkProperties1[i][metric][0])\n",
    "\n",
    "print(sorted(metrics0['Average_Degree']))\n",
    "print(sorted(metrics1['Average_Degree']))\n",
    "\n",
    "pvals = {key: None for key in metric_names}\n",
    "for metric in metric_names:\n",
    "    pvals[metric] = []\n",
    "    pvals[metric].append(np.mean(np.array(metrics0[metric])))\n",
    "    pvals[metric].append(np.mean(np.array(metrics1[metric])))\n",
    "    pvals[metric].append(stats.ttest_ind(np.array(metrics0[metric]), np.array(metrics1[metric]))[1])\n",
    "comparison = pd.DataFrame(data=pvals, index=[\"Healthy Mean\", \"Schizophrenic Mean\", \"p-value\"])\n",
    "comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "874d09ff6c0d950fd4fb409d1c762e7256626cd3bca414112760ab7b12f9e308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
